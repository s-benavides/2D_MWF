{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0IcAKJ4Muu2j"
   },
   "source": [
    "# Dedalus: 2D MWF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "O9tLGLNHqpqo",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob as glob\n",
    "import h5py\n",
    "import matplotlib.cm as cm\n",
    "from importlib import import_module\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"mathtext.fontset\"] = \"cm\"\n",
    "plt.rcParams[\"font.serif\"] = \"Times New Roman\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortKeyFunc(s):\n",
    "    s = s.split('_')[-1] # s{num}.h5\n",
    "    s = s[1:-3] #num\n",
    "    return int(s)\n",
    "\n",
    "def read_dedalus(folder,intype='snapshots'):\n",
    "    if intype=='snapshots':\n",
    "        data = []\n",
    "        ss = sorted(glob.glob(folder+'/'+intype+'/'+intype+'*.h5'),key=sortKeyFunc)\n",
    "        for file in ss:\n",
    "            data.append(h5py.File(file,'r'))\n",
    "    elif intype=='time_series':\n",
    "        data = dict([])\n",
    "        ss = sorted(glob.glob(folder+'/'+intype+'/'+intype+'*.h5'),key=sortKeyFunc)\n",
    "        for ii,file in enumerate(ss):\n",
    "            if ii==0:\n",
    "                data['time'] = h5py.File(file,'r')['scales']['sim_time']\n",
    "                data['timestep'] = h5py.File(file,'r')['scales']['iteration']\n",
    "            else:\n",
    "                data['time'] = np.hstack((data['time'],h5py.File(file,'r')['scales']['sim_time']))\n",
    "                data['timestep'] = h5py.File(file,'r')['scales']['iteration']\n",
    "\n",
    "        temp = h5py.File(ss[0],'r')\n",
    "        tasks = list(temp['tasks'].keys())\n",
    "        for task in tasks:\n",
    "            for ii,file in enumerate(ss):\n",
    "                if ii==0:\n",
    "                    data[task] = h5py.File(file,'r')['tasks'][task][:,0,0]\n",
    "                else:\n",
    "                    data[task] = np.hstack((data[task],h5py.File(file,'r')['tasks'][task][:,0,0]))\n",
    "        data['len_ss'] = len(ss)\n",
    "    return data\n",
    "\n",
    "def snapshot_slice(n,data,field):\n",
    "    for ii,subdat in enumerate(data):\n",
    "        if np.any(subdat['scales']['write_number'][:]==n):\n",
    "            n_m = np.squeeze(np.where(subdat['scales']['write_number'][:]==n))\n",
    "            s = ii\n",
    "    return [s,n_m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3jyf4QFvwgIt"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose input directory\n",
    "idir = '../'\n",
    "\n",
    "# Choose output directory\n",
    "odir = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lx224Lz100_Re75_tube_minimal']\n",
      "[75.]\n"
     ]
    }
   ],
   "source": [
    "# Searches through all directories in 'Data' folder (which are named after experiments) and imports the data:\n",
    "dirs = sorted(glob.glob(idir+'Lx224*tube*minimal*'))\n",
    "\n",
    "runs = []\n",
    "Res = []\n",
    "for file in dirs:\n",
    "    run = file.split('/')[1]\n",
    "\n",
    "    # Res\n",
    "    Re = float(run.split('_')[1][2:].replace('d','.'))\n",
    "    Res.append(Re)\n",
    "    runs.append(run)\n",
    "    \n",
    "    \n",
    "Res = np.array(Res)\n",
    "runs = np.array(runs)\n",
    "argRes = Res.argsort()\n",
    "Res = Res[argRes]\n",
    "runs = runs[argRes]\n",
    "Res = np.unique(Res)\n",
    "print(runs)\n",
    "print(Res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the data for each run now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict([])\n",
    "for run in runs:\n",
    "    data[run] = read_dedalus(idir+run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SIcO0LVq2nP2"
   },
   "source": [
    "Let's see what is in our imported variables.\n",
    "\n",
    "We saved the data in what's called a 'dictionary', which names its variables with strings. To see the experiments do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "kyfd9qwcz7lI",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "4dff24d4-f40e-4b02-b743-0df046e92fc1"
   },
   "outputs": [],
   "source": [
    "for run in runs:\n",
    "    print(run)\n",
    "    print(data[run])\n",
    "    for subdat in data[run]:\n",
    "        print(subdat['scales'].keys())\n",
    "        print(subdat['tasks'].keys())\n",
    "#         print(subdat['scales']['sim_time'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in data:\n",
    "    print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "OX3EqQs1FvRD",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "t_data = dict([])\n",
    "for run in runs:\n",
    "    try:\n",
    "        print(run)\n",
    "        t_data[run] = read_dedalus(idir+run,intype='time_series')\n",
    "    except Exception as e:\n",
    "        print(run,\"NO DATA\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_data = dict([])\n",
    "for run in runs:\n",
    "    file = str(run+'/params').replace('/','.')\n",
    "    params = import_module(file)\n",
    "    params_data[run] = params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bARgEvc199D9"
   },
   "source": [
    "# Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in t_data:\n",
    "    print(run,t_data[run]['timestep'][-1],t_data[run]['time'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose run\n",
    "lw  = 2.5\n",
    "alpha = 1\n",
    "Res_temp = np.copy(Res)\n",
    "minscale = np.nan\n",
    "maxscale = np.nan\n",
    "meansu = []\n",
    "meansq = []\n",
    "alist = []\n",
    "stds = []\n",
    "for ii,run in enumerate(t_data): \n",
    "    Re = float(run.split('_')[1][2:].replace('d','.'))\n",
    "    ls = '-'\n",
    "    label='Re = %s' % int(Re)\n",
    "    \n",
    "    time = t_data[run]['time'][:]\n",
    "    KE = t_data[run]['en_ls'][:]\n",
    "    plt.figure(1,figsize=(10,6))\n",
    "    plt.plot(time,KE,marker='',label = run)\n",
    "    \n",
    "    KE = t_data[run]['q0'][:]\n",
    "    plt.figure(2,figsize=(10,6))\n",
    "    plt.plot(time,KE,marker='',label = run)\n",
    "    \n",
    "    KE = t_data[run]['q1'][:]\n",
    "    plt.figure(3,figsize=(10,6))\n",
    "    plt.plot(time,KE,marker='',label = run)#,c=((Re-np.min(Res))/(np.max(Res)-np.min(Res)),0,0,1),lw=lw,ls = ls,alpha=alpha,label=Re)\n",
    "            \n",
    "log_yax = False\n",
    "\n",
    "plt.figure(1,figsize=(10,6))\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"KE_ls\")\n",
    "plt.legend(fontsize=15,loc=(1.01,0.0))\n",
    "if log_yax:\n",
    "    plt.gca().set_yscale('log')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(2,figsize=(10,6))\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"q0\")\n",
    "plt.legend(fontsize=15,loc=(1.01,0.0))\n",
    "if log_yax:\n",
    "    plt.gca().set_yscale('log')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(3,figsize=(10,6))\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"q1\")\n",
    "plt.legend(fontsize=15,loc=(1.01,0.0))\n",
    "if log_yax:\n",
    "    plt.gca().set_yscale('log')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RediaYQd3Zq8"
   },
   "source": [
    "# Snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "KXk38yAm3YSN",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "995e5ef2-be47-4b73-fc19-1791f3e7153b"
   },
   "outputs": [],
   "source": [
    "runs_snaps = np.copy(runs)\n",
    "plt.figure(figsize=(8,6))\n",
    "for run in runs_snaps[:]:\n",
    "    Re = float(run.split('_')[1][2:].replace('d','.'))\n",
    "    n_max = data[run][-1]['scales']['write_number'][-1] # n_max is frame number, but with python we have to subtract one\n",
    "    n = np.min([n_max,n_max])\n",
    "    print(\"n_max = %s\" % n_max)\n",
    "    s,n = snapshot_slice(n,data[run],'u0')\n",
    "\n",
    "    # Read info:\n",
    "    time = data[run][s]['scales']['sim_time'][n]\n",
    "\n",
    "    # Define array for x and z axes\n",
    "    X = data[run][s]['scales']['x']['1.0'][:]\n",
    "    Z = data[run][s]['scales']['z']['1.0'][:]\n",
    "    Lx = np.max(X)\n",
    "    Lz = np.max(Z)\n",
    "\n",
    "    size = 10\n",
    "    plt.figure(figsize=(10*3/2,6))#2*size,size*(H/L)))\n",
    "\n",
    "    u0 = data[run][s]['tasks']['u0'][n,:,:]\n",
    "    w0 = data[run][s]['tasks']['w0'][n,:,:]\n",
    "    q0 = data[run][s]['tasks']['q0'][n,:,:]\n",
    "\n",
    "    # Plot the turbulence\n",
    "    Re = float(run.split('_')[1][2:].replace('d','.'))\n",
    "    plt.pcolormesh(X,Z,q0.T,vmin=0,vmax=np.max(q0[:]),cmap= cm.copper)\n",
    "    plt.colorbar(label=r'$q_0$')\n",
    "\n",
    "    # Now the flow field\n",
    "    from scipy.interpolate import interp2d\n",
    "\n",
    "    # regularly spaced grid spanning the domain of x and y \n",
    "    Xi = np.linspace(X.min(), X.max(), int(X.size/2))\n",
    "    Zi = np.linspace(Z.min(), Z.max(), int(Z.size/2))\n",
    "\n",
    "    # bicubic interpolation\n",
    "    ru = interp2d(X,Z, u0.T)(Xi, Zi)\n",
    "    rw = interp2d(X,Z, w0.T)(Xi, Zi)\n",
    "\n",
    "    plt.streamplot(Xi, Zi, ru, rw,color='w',density = [0.5,0.5])#,density =[0.4, 0.4],arrowsize=0.0,minlength=0.3)\n",
    "\n",
    "    plt.xlabel(r\"$x$\")\n",
    "    plt.ylabel(r\"$z$\")\n",
    "    plt.xlim(0,Lx)\n",
    "    plt.ylim(0,Lz)\n",
    "    plt.gca().set_aspect(1)\n",
    "    plt.title(run+r' time = %f' % time,fontsize=15)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Data_Visualization.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
